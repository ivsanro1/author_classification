{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a7c6b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "# Override/set credentials in env var\n",
    "os.environ['CWD'] = str(Path(os.getcwd()).parent)\n",
    "\n",
    "# Base paths\n",
    "cwd = Path(os.environ['CWD'])\n",
    "dir_data = cwd / 'data'\n",
    "dir_models = cwd / 'models'\n",
    "dir_models.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "import pickle\n",
    "def picklesave(o, f):\n",
    "    with open(f, 'wb') as fp:\n",
    "        pickle.dump(o, fp)\n",
    "        \n",
    "def pickleload(f):\n",
    "    with open(f, 'rb') as fp:\n",
    "        return pickle.load(fp)\n",
    "\n",
    "\n",
    "from tqdm import tqdm \n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18a15b7",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8d4743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_tr_ev = pd.read_csv(dir_data / 'train.csv')\n",
    "df_tr_ev['split'] = 'tr'\n",
    "df_te = pd.read_csv(dir_data / 'test.csv')\n",
    "df_te['split'] = 'te'\n",
    "\n",
    "df = pd.concat([df_tr_ev, df_te])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9482ce3d",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2427e04c",
   "metadata": {},
   "source": [
    "## Set punctuation features (statistics) from unprocessed texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b6b433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 18:09:44.342001: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-26 18:09:44.342045: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "100%|███████████████████████████████████| 40000/40000 [00:09<00:00, 4442.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from author_classification.feature_extraction import get_text_punctuation_stat_features\n",
    "df_tr_ev['dict_punct_features'] = df_tr_ev['text'].progress_apply(get_text_punctuation_stat_features)\n",
    "\n",
    "# Put each punctuation feature in a column in the dataframe\n",
    "from author_classification.utils import expand_col_dicts\n",
    "df_tr_ev = expand_col_dicts(df_tr_ev, colname_dict='dict_punct_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b94dd3",
   "metadata": {},
   "source": [
    "## Sentiment and readability from unprocessed texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c905152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [00:46<00:00,  3.12s/it]\n",
      "100%|███████████████████████████████████| 40000/40000 [00:17<00:00, 2349.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from author_classification.feature_extraction import (\n",
    "    set_text_readability_statistics, set_text_polarity_subjectivity, LIST_TUPLES_READABILITY_STATISTICS\n",
    ")\n",
    "df_tr_ev = set_text_readability_statistics(df_tr_ev, colname_text='text')\n",
    "df_tr_ev = set_text_polarity_subjectivity(df_tr_ev, colname_text='text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be548b58",
   "metadata": {},
   "source": [
    "## Preprocess texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddb2c3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 40000/40000 [03:04<00:00, 216.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess text\n",
    "from author_classification.preprocessing import preprocess_text\n",
    "# We should also make another column\n",
    "df_tr_ev['text_processed'] = df_tr_ev['text'].progress_apply(lambda txt: preprocess_text(txt, lemmatize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9406c26c",
   "metadata": {},
   "source": [
    "## n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02534713",
   "metadata": {},
   "source": [
    "### Split dataset now to avoid data leakage in tfidf and tsvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdee6053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_tr, df_ev = train_test_split(df_tr_ev, test_size=0.15, stratify=df_tr_ev['author'], random_state=288)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b49e30",
   "metadata": {},
   "source": [
    "### Char-level tfidf on unprocessed texts\n",
    "Capture fine-grain char-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7acf4024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61903 features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_char = TfidfVectorizer(\n",
    "    ngram_range=(1,5),\n",
    "    analyzer='char',\n",
    "    min_df=40,\n",
    "    max_df=0.7\n",
    ")\n",
    "\n",
    "X_tfidf_char_tr = tfidf_char.fit_transform(df_tr['text']).astype(np.float32)\n",
    "print(f'{len(tfidf_char.vocabulary_)} features')\n",
    "X_tfidf_char_ev = tfidf_char.transform(df_ev['text']).astype(np.float32)\n",
    "\n",
    "picklesave(tfidf_char, dir_models / 'tfidf_char.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412c1235",
   "metadata": {},
   "source": [
    "### Reduce dimensionality with TSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad3edae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative sum of explained variance ratio kept by tsvd_char: 0.4212000072002411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "tsvd_char = TruncatedSVD(n_components=1000, random_state=288)\n",
    "X_tfidf_char_tsvd_tr = tsvd_char.fit_transform(X_tfidf_char_tr)\n",
    "print(f'Cumulative sum of explained variance ratio kept by tsvd_char: {round(tsvd_char.explained_variance_ratio_.cumsum()[-1], 4)}')\n",
    "X_tfidf_char_tsvd_ev = tsvd_char.transform(X_tfidf_char_ev)\n",
    "\n",
    "picklesave(tsvd_char, dir_models / 'tsvd_char.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de1627",
   "metadata": {},
   "source": [
    "### Word-level tfidf on processed texts\n",
    "Capture coarse-grained word-level features, relations between words, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f12a3e",
   "metadata": {},
   "source": [
    "#### Fit word-level tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ecce859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29243 features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_word = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    analyzer='word',\n",
    "    min_df=5,\n",
    "    max_df=0.7\n",
    ")\n",
    "\n",
    "X_tfidf_word_tr = tfidf_word.fit_transform(df_tr['text_processed']).astype(np.float32)\n",
    "print(f'{len(tfidf_word.vocabulary_)} features')\n",
    "X_tfidf_word_ev = tfidf_word.transform(df_ev['text_processed']).astype(np.float32)\n",
    "\n",
    "picklesave(tfidf_word, dir_models / 'tfidf_word.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8961f14a",
   "metadata": {},
   "source": [
    "### Reduce dimensionality with TSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9dd0e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative sum of explained variance ratio kept by tsvd_word: 0.44040000438690186\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "tsvd_word = TruncatedSVD(n_components=1500, random_state=288)\n",
    "X_tfidf_word_tsvd_tr = tsvd_word.fit_transform(X_tfidf_word_tr)\n",
    "print(f'Cumulative sum of explained variance ratio kept by tsvd_word: {round(tsvd_word.explained_variance_ratio_.cumsum()[-1], 4)}')\n",
    "X_tfidf_word_tsvd_ev = tsvd_word.transform(X_tfidf_word_ev)\n",
    "\n",
    "picklesave(tsvd_word, dir_models / 'tsvd_word.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4588d5",
   "metadata": {},
   "source": [
    "# Preparing data to train + eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90b82db",
   "metadata": {},
   "source": [
    "## Get punctuation, sentiment and readability feature vectors for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "610b8a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from author_classification.feature_extraction import get_feature_matrix_from_dataframe_with_feature_columns\n",
    "\n",
    "X_tr_stats = get_feature_matrix_from_dataframe_with_feature_columns(df_tr)\n",
    "X_ev_stats = get_feature_matrix_from_dataframe_with_feature_columns(df_ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6539e2",
   "metadata": {},
   "source": [
    "### Scale these punctuation, sentiment and readability features as they are independent of each other (we are not interested in the angle defined by these)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4072cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_tr_stats_scaled = scaler.fit_transform(X_tr_stats)\n",
    "X_ev_stats_scaled = scaler.transform(X_ev_stats)\n",
    "picklesave(scaler, dir_models / 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450e09e",
   "metadata": {},
   "source": [
    "## Extract sentence vectors with pretrained model for Sentence Similarity\n",
    "This is to also help the model capture the semantic features of the passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8139b033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f225e8e5574a40889fde1802c83f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d72f74c63142e08c01d83490ed0ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model_sent_embs = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "X_sentembs_tr = model_sent_embs.encode(df_tr['text'].values, show_progress_bar=True)\n",
    "X_sentembs_ev = model_sent_embs.encode(df_ev['text'].values, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e4d64f",
   "metadata": {},
   "source": [
    "## Concatenate all features\n",
    "Concatenated features consist of:\n",
    "- Character features\n",
    "- Word features\n",
    "- Punctuation, sentiment and readability features\n",
    "- Semantic embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a2461ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.hstack([X_tr_stats_scaled, X_tfidf_char_tsvd_tr, X_tfidf_word_tsvd_tr, X_sentembs_tr])\n",
    "X_ev = np.hstack([X_ev_stats_scaled, X_tfidf_char_tsvd_ev, X_tfidf_word_tsvd_ev, X_sentembs_ev])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d143a5",
   "metadata": {},
   "source": [
    "## Preprocess labels for keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da51b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "le = OneHotEncoder()\n",
    "Y_tr = le.fit_transform(df_tr['author'].values.reshape(-1,1))\n",
    "Y_ev = le.transform(df_ev['author'].values.reshape(-1,1))\n",
    "# Save label encoder too to use it when inferring\n",
    "picklesave(le, dir_models / 'le.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81adcbf5",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182c0d7c",
   "metadata": {},
   "source": [
    "## Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf5dc591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2920)]            0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, 2920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                93472     \n",
      "_________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "gaussian_noise_2 (GaussianNo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 94,660\n",
      "Trainable params: 94,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 18:32:58.118063: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-26 18:32:58.118108: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-26 18:32:58.118130: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (16c147a04f9e): /proc/driver/nvidia/version does not exist\n",
      "2022-04-26 18:32:58.118286: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from author_classification.modeling import get_model\n",
    "clf = get_model(input_shape=X_tr.shape[1], n_classes=Y_tr.shape[1])\n",
    "clf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653f480f",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aaeb3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 18:32:58.608921: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 397120000 exceeds 10% of free system memory.\n",
      "2022-04-26 18:32:59.087677: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-26 18:32:59.093510: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2592005000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "532/532 [==============================] - 3s 4ms/step - loss: 0.5079 - categorical_accuracy: 0.8175 - val_loss: 0.2622 - val_categorical_accuracy: 0.8998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 18:33:01.647118: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 70080000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2858 - categorical_accuracy: 0.9014 - val_loss: 0.2226 - val_categorical_accuracy: 0.9180\n",
      "Epoch 3/1000\n",
      "532/532 [==============================] - 2s 3ms/step - loss: 0.2545 - categorical_accuracy: 0.9117 - val_loss: 0.2159 - val_categorical_accuracy: 0.9205\n",
      "Epoch 4/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2482 - categorical_accuracy: 0.9141 - val_loss: 0.2148 - val_categorical_accuracy: 0.9212\n",
      "Epoch 5/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2465 - categorical_accuracy: 0.9150 - val_loss: 0.2144 - val_categorical_accuracy: 0.9213\n",
      "Epoch 6/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2480 - categorical_accuracy: 0.9139 - val_loss: 0.2144 - val_categorical_accuracy: 0.9212\n",
      "Epoch 7/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2485 - categorical_accuracy: 0.9152 - val_loss: 0.2143 - val_categorical_accuracy: 0.9210\n",
      "Epoch 8/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2485 - categorical_accuracy: 0.9147 - val_loss: 0.2143 - val_categorical_accuracy: 0.9210\n",
      "Epoch 9/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2478 - categorical_accuracy: 0.9142 - val_loss: 0.2143 - val_categorical_accuracy: 0.9210\n",
      "Epoch 10/1000\n",
      "532/532 [==============================] - 2s 3ms/step - loss: 0.2493 - categorical_accuracy: 0.9158 - val_loss: 0.2142 - val_categorical_accuracy: 0.9210\n",
      "Epoch 11/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2500 - categorical_accuracy: 0.9156 - val_loss: 0.2142 - val_categorical_accuracy: 0.9210\n",
      "Epoch 12/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2458 - categorical_accuracy: 0.9153 - val_loss: 0.2142 - val_categorical_accuracy: 0.9210\n",
      "Epoch 13/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2473 - categorical_accuracy: 0.9160 - val_loss: 0.2142 - val_categorical_accuracy: 0.9208\n",
      "Epoch 14/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2427 - categorical_accuracy: 0.9154 - val_loss: 0.2141 - val_categorical_accuracy: 0.9208\n",
      "Epoch 15/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2494 - categorical_accuracy: 0.9135 - val_loss: 0.2141 - val_categorical_accuracy: 0.9207\n",
      "Epoch 16/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2472 - categorical_accuracy: 0.9144 - val_loss: 0.2141 - val_categorical_accuracy: 0.9207\n",
      "Epoch 17/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2472 - categorical_accuracy: 0.9164 - val_loss: 0.2140 - val_categorical_accuracy: 0.9207\n",
      "Epoch 18/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2522 - categorical_accuracy: 0.9125 - val_loss: 0.2140 - val_categorical_accuracy: 0.9207\n",
      "Epoch 19/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2476 - categorical_accuracy: 0.9139 - val_loss: 0.2140 - val_categorical_accuracy: 0.9207\n",
      "Epoch 20/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2460 - categorical_accuracy: 0.9149 - val_loss: 0.2139 - val_categorical_accuracy: 0.9205\n",
      "Epoch 21/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2480 - categorical_accuracy: 0.9135 - val_loss: 0.2139 - val_categorical_accuracy: 0.9208\n",
      "Epoch 22/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2472 - categorical_accuracy: 0.9153 - val_loss: 0.2139 - val_categorical_accuracy: 0.9208\n",
      "Epoch 23/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2500 - categorical_accuracy: 0.9140 - val_loss: 0.2138 - val_categorical_accuracy: 0.9208\n",
      "Epoch 24/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2462 - categorical_accuracy: 0.9143 - val_loss: 0.2138 - val_categorical_accuracy: 0.9208\n",
      "Epoch 25/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2456 - categorical_accuracy: 0.9159 - val_loss: 0.2138 - val_categorical_accuracy: 0.9208\n",
      "Epoch 26/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2463 - categorical_accuracy: 0.9173 - val_loss: 0.2137 - val_categorical_accuracy: 0.9208\n",
      "Epoch 27/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2485 - categorical_accuracy: 0.9139 - val_loss: 0.2137 - val_categorical_accuracy: 0.9207\n",
      "Epoch 28/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2457 - categorical_accuracy: 0.9172 - val_loss: 0.2137 - val_categorical_accuracy: 0.9207\n",
      "Epoch 29/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2505 - categorical_accuracy: 0.9151 - val_loss: 0.2137 - val_categorical_accuracy: 0.9205\n",
      "Epoch 30/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2453 - categorical_accuracy: 0.9157 - val_loss: 0.2136 - val_categorical_accuracy: 0.9207\n",
      "Epoch 31/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2460 - categorical_accuracy: 0.9138 - val_loss: 0.2136 - val_categorical_accuracy: 0.9207\n",
      "Epoch 32/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2474 - categorical_accuracy: 0.9148 - val_loss: 0.2136 - val_categorical_accuracy: 0.9208\n",
      "Epoch 33/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2469 - categorical_accuracy: 0.9149 - val_loss: 0.2135 - val_categorical_accuracy: 0.9207\n",
      "Epoch 34/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2496 - categorical_accuracy: 0.9146 - val_loss: 0.2135 - val_categorical_accuracy: 0.9207\n",
      "Epoch 35/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2465 - categorical_accuracy: 0.9148 - val_loss: 0.2135 - val_categorical_accuracy: 0.9207\n",
      "Epoch 36/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2462 - categorical_accuracy: 0.9139 - val_loss: 0.2134 - val_categorical_accuracy: 0.9208\n",
      "Epoch 37/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2439 - categorical_accuracy: 0.9148 - val_loss: 0.2134 - val_categorical_accuracy: 0.9210\n",
      "Epoch 38/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2464 - categorical_accuracy: 0.9156 - val_loss: 0.2134 - val_categorical_accuracy: 0.9212\n",
      "Epoch 39/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2490 - categorical_accuracy: 0.9148 - val_loss: 0.2134 - val_categorical_accuracy: 0.9212\n",
      "Epoch 40/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2447 - categorical_accuracy: 0.9161 - val_loss: 0.2133 - val_categorical_accuracy: 0.9212\n",
      "Epoch 41/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2465 - categorical_accuracy: 0.9150 - val_loss: 0.2133 - val_categorical_accuracy: 0.9215\n",
      "Epoch 42/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2500 - categorical_accuracy: 0.9154 - val_loss: 0.2133 - val_categorical_accuracy: 0.9213\n",
      "Epoch 43/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2404 - categorical_accuracy: 0.9169 - val_loss: 0.2132 - val_categorical_accuracy: 0.9213\n",
      "Epoch 44/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2480 - categorical_accuracy: 0.9149 - val_loss: 0.2132 - val_categorical_accuracy: 0.9215\n",
      "Epoch 45/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2470 - categorical_accuracy: 0.9155 - val_loss: 0.2132 - val_categorical_accuracy: 0.9212\n",
      "Epoch 46/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2509 - categorical_accuracy: 0.9139 - val_loss: 0.2132 - val_categorical_accuracy: 0.9215\n",
      "Epoch 47/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2499 - categorical_accuracy: 0.9144 - val_loss: 0.2131 - val_categorical_accuracy: 0.9215\n",
      "Epoch 48/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2443 - categorical_accuracy: 0.9163 - val_loss: 0.2131 - val_categorical_accuracy: 0.9215\n",
      "Epoch 49/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2467 - categorical_accuracy: 0.9161 - val_loss: 0.2131 - val_categorical_accuracy: 0.9215\n",
      "Epoch 50/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2443 - categorical_accuracy: 0.9153 - val_loss: 0.2130 - val_categorical_accuracy: 0.9215\n",
      "Epoch 51/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2444 - categorical_accuracy: 0.9148 - val_loss: 0.2130 - val_categorical_accuracy: 0.9217\n",
      "Epoch 52/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2462 - categorical_accuracy: 0.9149 - val_loss: 0.2130 - val_categorical_accuracy: 0.9217\n",
      "Epoch 53/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2494 - categorical_accuracy: 0.9149 - val_loss: 0.2129 - val_categorical_accuracy: 0.9217\n",
      "Epoch 54/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2453 - categorical_accuracy: 0.9149 - val_loss: 0.2129 - val_categorical_accuracy: 0.9217\n",
      "Epoch 55/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2455 - categorical_accuracy: 0.9145 - val_loss: 0.2129 - val_categorical_accuracy: 0.9218\n",
      "Epoch 56/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2466 - categorical_accuracy: 0.9138 - val_loss: 0.2129 - val_categorical_accuracy: 0.9218\n",
      "Epoch 57/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2475 - categorical_accuracy: 0.9148 - val_loss: 0.2128 - val_categorical_accuracy: 0.9220\n",
      "Epoch 58/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2480 - categorical_accuracy: 0.9139 - val_loss: 0.2128 - val_categorical_accuracy: 0.9220\n",
      "Epoch 59/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2477 - categorical_accuracy: 0.9165 - val_loss: 0.2128 - val_categorical_accuracy: 0.9218\n",
      "Epoch 60/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2442 - categorical_accuracy: 0.9168 - val_loss: 0.2128 - val_categorical_accuracy: 0.9220\n",
      "Epoch 61/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2475 - categorical_accuracy: 0.9154 - val_loss: 0.2127 - val_categorical_accuracy: 0.9218\n",
      "Epoch 62/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2442 - categorical_accuracy: 0.9158 - val_loss: 0.2127 - val_categorical_accuracy: 0.9218\n",
      "Epoch 63/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2458 - categorical_accuracy: 0.9161 - val_loss: 0.2127 - val_categorical_accuracy: 0.9220\n",
      "Epoch 64/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2437 - categorical_accuracy: 0.9158 - val_loss: 0.2126 - val_categorical_accuracy: 0.9218\n",
      "Epoch 65/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2437 - categorical_accuracy: 0.9160 - val_loss: 0.2126 - val_categorical_accuracy: 0.9218\n",
      "Epoch 66/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2437 - categorical_accuracy: 0.9178 - val_loss: 0.2126 - val_categorical_accuracy: 0.9218\n",
      "Epoch 67/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2461 - categorical_accuracy: 0.9150 - val_loss: 0.2126 - val_categorical_accuracy: 0.9218\n",
      "Epoch 68/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2468 - categorical_accuracy: 0.9162 - val_loss: 0.2125 - val_categorical_accuracy: 0.9218\n",
      "Epoch 69/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2453 - categorical_accuracy: 0.9174 - val_loss: 0.2125 - val_categorical_accuracy: 0.9218\n",
      "Epoch 70/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2453 - categorical_accuracy: 0.9167 - val_loss: 0.2125 - val_categorical_accuracy: 0.9218\n",
      "Epoch 71/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2473 - categorical_accuracy: 0.9138 - val_loss: 0.2125 - val_categorical_accuracy: 0.9218\n",
      "Epoch 72/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2442 - categorical_accuracy: 0.9165 - val_loss: 0.2124 - val_categorical_accuracy: 0.9218\n",
      "Epoch 73/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2473 - categorical_accuracy: 0.9153 - val_loss: 0.2124 - val_categorical_accuracy: 0.9218\n",
      "Epoch 74/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2478 - categorical_accuracy: 0.9139 - val_loss: 0.2124 - val_categorical_accuracy: 0.9218\n",
      "Epoch 75/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2465 - categorical_accuracy: 0.9156 - val_loss: 0.2124 - val_categorical_accuracy: 0.9218\n",
      "Epoch 76/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2441 - categorical_accuracy: 0.9168 - val_loss: 0.2124 - val_categorical_accuracy: 0.9218\n",
      "Epoch 77/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2428 - categorical_accuracy: 0.9167 - val_loss: 0.2124 - val_categorical_accuracy: 0.9218\n",
      "Epoch 78/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2435 - categorical_accuracy: 0.9170 - val_loss: 0.2123 - val_categorical_accuracy: 0.9218\n",
      "Epoch 79/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2455 - categorical_accuracy: 0.9148 - val_loss: 0.2123 - val_categorical_accuracy: 0.9218\n",
      "Epoch 80/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2468 - categorical_accuracy: 0.9163 - val_loss: 0.2123 - val_categorical_accuracy: 0.9218\n",
      "Epoch 81/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2453 - categorical_accuracy: 0.9155 - val_loss: 0.2123 - val_categorical_accuracy: 0.9218\n",
      "Epoch 82/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2434 - categorical_accuracy: 0.9166 - val_loss: 0.2122 - val_categorical_accuracy: 0.9218\n",
      "Epoch 83/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2424 - categorical_accuracy: 0.9152 - val_loss: 0.2122 - val_categorical_accuracy: 0.9220\n",
      "Epoch 84/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2453 - categorical_accuracy: 0.9151 - val_loss: 0.2122 - val_categorical_accuracy: 0.9218\n",
      "Epoch 85/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2462 - categorical_accuracy: 0.9163 - val_loss: 0.2122 - val_categorical_accuracy: 0.9217\n",
      "Epoch 86/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2453 - categorical_accuracy: 0.9154 - val_loss: 0.2121 - val_categorical_accuracy: 0.9218\n",
      "Epoch 87/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2408 - categorical_accuracy: 0.9161 - val_loss: 0.2121 - val_categorical_accuracy: 0.9218\n",
      "Epoch 88/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2434 - categorical_accuracy: 0.9155 - val_loss: 0.2121 - val_categorical_accuracy: 0.9218\n",
      "Epoch 89/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2423 - categorical_accuracy: 0.9163 - val_loss: 0.2121 - val_categorical_accuracy: 0.9217\n",
      "Epoch 90/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2466 - categorical_accuracy: 0.9147 - val_loss: 0.2121 - val_categorical_accuracy: 0.9217\n",
      "Epoch 91/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2455 - categorical_accuracy: 0.9151 - val_loss: 0.2120 - val_categorical_accuracy: 0.9217\n",
      "Epoch 92/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2447 - categorical_accuracy: 0.9166 - val_loss: 0.2120 - val_categorical_accuracy: 0.9217\n",
      "Epoch 93/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2425 - categorical_accuracy: 0.9165 - val_loss: 0.2120 - val_categorical_accuracy: 0.9218\n",
      "Epoch 94/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2459 - categorical_accuracy: 0.9147 - val_loss: 0.2119 - val_categorical_accuracy: 0.9218\n",
      "Epoch 95/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2445 - categorical_accuracy: 0.9168 - val_loss: 0.2119 - val_categorical_accuracy: 0.9218\n",
      "Epoch 96/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2435 - categorical_accuracy: 0.9168 - val_loss: 0.2119 - val_categorical_accuracy: 0.9220\n",
      "Epoch 97/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2415 - categorical_accuracy: 0.9174 - val_loss: 0.2118 - val_categorical_accuracy: 0.9220\n",
      "Epoch 98/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2453 - categorical_accuracy: 0.9151 - val_loss: 0.2118 - val_categorical_accuracy: 0.9220\n",
      "Epoch 99/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2437 - categorical_accuracy: 0.9154 - val_loss: 0.2118 - val_categorical_accuracy: 0.9220\n",
      "Epoch 100/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2398 - categorical_accuracy: 0.9161 - val_loss: 0.2118 - val_categorical_accuracy: 0.9220\n",
      "Epoch 101/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2430 - categorical_accuracy: 0.9165 - val_loss: 0.2118 - val_categorical_accuracy: 0.9220\n",
      "Epoch 102/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2436 - categorical_accuracy: 0.9151 - val_loss: 0.2117 - val_categorical_accuracy: 0.9220\n",
      "Epoch 103/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2457 - categorical_accuracy: 0.9149 - val_loss: 0.2117 - val_categorical_accuracy: 0.9220\n",
      "Epoch 104/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2438 - categorical_accuracy: 0.9156 - val_loss: 0.2117 - val_categorical_accuracy: 0.9220\n",
      "Epoch 105/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2436 - categorical_accuracy: 0.9159 - val_loss: 0.2117 - val_categorical_accuracy: 0.9220\n",
      "Epoch 106/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2409 - categorical_accuracy: 0.9162 - val_loss: 0.2117 - val_categorical_accuracy: 0.9220\n",
      "Epoch 107/1000\n",
      "532/532 [==============================] - 2s 4ms/step - loss: 0.2427 - categorical_accuracy: 0.9171 - val_loss: 0.2116 - val_categorical_accuracy: 0.9218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f70595cca90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import (EarlyStopping, ModelCheckpoint,\n",
    "                                        ReduceLROnPlateau)\n",
    "callbacks = []\n",
    "callbacks.append(EarlyStopping(monitor='val_categorical_accuracy', patience=50, verbose=0, mode='max'))\n",
    "callbacks.append(ModelCheckpoint(dir_models / 'clf.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max', save_weights_only=False))\n",
    "\n",
    "     \n",
    "clf.fit(\n",
    "    x=X_tr,\n",
    "    y=Y_tr.todense(),\n",
    "    batch_size=64,\n",
    "    epochs=1000,\n",
    "    validation_data=(\n",
    "        X_ev,\n",
    "        Y_ev.todense()\n",
    "    ),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f406e782",
   "metadata": {},
   "source": [
    "## Load model at best epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8be919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from author_classification.modeling import scale_fn # Needed to load the model\n",
    "\n",
    "clf_best = load_model(dir_models / 'clf.h5', custom_objects={'scale_fn': scale_fn})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa3e7ce",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf1220fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 18:36:27.542446: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 397120000 exceeds 10% of free system memory.\n",
      "2022-04-26 18:36:28.582586: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 70080000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "Y_hat_tr = le.inverse_transform(clf_best.predict(X_tr))\n",
    "Y_hat_ev = le.inverse_transform(clf_best.predict(X_ev))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d5f397",
   "metadata": {},
   "source": [
    "## Evaluate on training data (to see how much overfitted it is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc95f858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       defoe       0.97      0.98      0.97      8500\n",
      "     dickens       0.94      0.92      0.93      8500\n",
      "       doyle       0.94      0.95      0.94      8500\n",
      "       twain       0.93      0.94      0.93      8500\n",
      "\n",
      "    accuracy                           0.95     34000\n",
      "   macro avg       0.95      0.95      0.95     34000\n",
      "weighted avg       0.95      0.95      0.95     34000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(df_tr['author'], Y_hat_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29776f30",
   "metadata": {},
   "source": [
    "## Evaluate on eval (dev) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4fcaac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       defoe       0.95      0.96      0.95      1500\n",
      "     dickens       0.92      0.89      0.90      1500\n",
      "       doyle       0.92      0.93      0.92      1500\n",
      "       twain       0.90      0.91      0.91      1500\n",
      "\n",
      "    accuracy                           0.92      6000\n",
      "   macro avg       0.92      0.92      0.92      6000\n",
      "weighted avg       0.92      0.92      0.92      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(df_ev['author'], Y_hat_ev))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e0da6",
   "metadata": {},
   "source": [
    "### Plot confusion matrix (eval data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8592556c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7012f90250>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from author_classification.confusion_matrix import plot_cm\n",
    "plot_cm(df_ev['author'], Y_hat_ev.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe47e60",
   "metadata": {},
   "source": [
    "### Show some examples of bad classifications (eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffc2019b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>author_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>Among these\\n      causes and effects, this of the secret conveyance of infection,\\n      imperceptible and unavoidable, is more than sufficient to execute\\n      the fierceness of Divine vengeance, without putting it upon\\n      supernaturals and miracle</td>\n",
       "      <td>defoe</td>\n",
       "      <td>dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6896</th>\n",
       "      <td>The\\nstory seems to be working itself out to a logical conclusion, when\\nunexpectedly it comes to an end. \\n\\nIt is not always necessary that the names of persons should be\\ndiscovered, though the history may be many ways useful; and if we should\\nbe always obliged to name the persons, or not to relate the story, the\\nconsequence might be only this--that many a pleasant and delightful\\nhistory would be buried in the dark, and the world deprived both of the\\npleasure and the profit of it</td>\n",
       "      <td>defoe</td>\n",
       "      <td>twain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10320</th>\n",
       "      <td>In three months more, a year would have passed since the\\nbeginning of my sorrow.  I determined to make no resolutions until the\\nexpiration of those three months, but to try.  I lived in that valley,\\nand its neighbourhood, all the time</td>\n",
       "      <td>dickens</td>\n",
       "      <td>twain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>I could ha’ got\\nclear of these death-cold flats likewise—look at my leg: you won’t find\\nmuch iron on it—if I hadn’t made the discovery that _he_ was here.  Let\\n_him_ go free? Let _him_ profit by the means as I found out? Let _him_\\nmake a tool of me afresh and again? Once more? No, no, no</td>\n",
       "      <td>dickens</td>\n",
       "      <td>defoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22928</th>\n",
       "      <td>We have a clear month before us; at\\nthe end of that, I guess we had best shin out of Utah. ”\\n\\n“Leave Utah!”\\n\\n“That’s about the size of it.  I’m a free-born American, and it’s all new to me.  Guess\\nI’m too old to learn</td>\n",
       "      <td>doyle</td>\n",
       "      <td>twain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22103</th>\n",
       "      <td>He took out a ten-pound note, and he held it\\nout to me then and there.  ‘You can have the same every fortnight for a\\nlong time to come if you keep the terms,’ he said.  ‘If not, I’ll have\\nno more to do with you</td>\n",
       "      <td>doyle</td>\n",
       "      <td>dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35918</th>\n",
       "      <td>\\n\\n“Let her go back on the labboard! Ting-a-ling-ling! Chow-ch-chow-chow!”\\n The left hand began to describe circles. \\n\\n“Stop the stabboard! Ting-a-ling-ling! Stop the labboard! Come ahead on\\nthe stabboard! Stop her! Let your outside turn over slow! Ting-a-ling-ling!\\nChow-ow-ow! Get out that head-line! _lively_ now! Come—out with\\nyour spring-line—what’re you about there! Take a turn round that stump\\nwith the bight of it! Stand by that stage, now—let her go! Done with\\nthe engines, sir! Ting-a-ling-ling! SH’T! S’H’T! SH’T!” (trying the\\ngauge-cocks)</td>\n",
       "      <td>twain</td>\n",
       "      <td>dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33653</th>\n",
       "      <td>”\\n\\n“Speak, and freely.   I will tell you. ”\\n\\n“It will be difficult--perhaps impossible. ”\\n\\n“My art knoweth not that word.   The more difficult it is, the more\\ncertainly will I reveal it to you. ”\\n\\n“The fortune is mine!  I will tell you what you would know</td>\n",
       "      <td>twain</td>\n",
       "      <td>doyle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    text  \\\n",
       "index                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "1434                                                                                                                                                                                                                                                                                                                     Among these\\n      causes and effects, this of the secret conveyance of infection,\\n      imperceptible and unavoidable, is more than sufficient to execute\\n      the fierceness of Divine vengeance, without putting it upon\\n      supernaturals and miracle   \n",
       "6896                                                                         The\\nstory seems to be working itself out to a logical conclusion, when\\nunexpectedly it comes to an end. \\n\\nIt is not always necessary that the names of persons should be\\ndiscovered, though the history may be many ways useful; and if we should\\nbe always obliged to name the persons, or not to relate the story, the\\nconsequence might be only this--that many a pleasant and delightful\\nhistory would be buried in the dark, and the world deprived both of the\\npleasure and the profit of it   \n",
       "10320                                                                                                                                                                                                                                                                                                                                      In three months more, a year would have passed since the\\nbeginning of my sorrow.  I determined to make no resolutions until the\\nexpiration of those three months, but to try.  I lived in that valley,\\nand its neighbourhood, all the time   \n",
       "10397                                                                                                                                                                                                                                                                               I could ha’ got\\nclear of these death-cold flats likewise—look at my leg: you won’t find\\nmuch iron on it—if I hadn’t made the discovery that _he_ was here.  Let\\n_him_ go free? Let _him_ profit by the means as I found out? Let _him_\\nmake a tool of me afresh and again? Once more? No, no, no   \n",
       "22928                                                                                                                                                                                                                                                                                                                                                    We have a clear month before us; at\\nthe end of that, I guess we had best shin out of Utah. ”\\n\\n“Leave Utah!”\\n\\n“That’s about the size of it.  I’m a free-born American, and it’s all new to me.  Guess\\nI’m too old to learn   \n",
       "22103                                                                                                                                                                                                                                                                                                                                                              He took out a ten-pound note, and he held it\\nout to me then and there.  ‘You can have the same every fortnight for a\\nlong time to come if you keep the terms,’ he said.  ‘If not, I’ll have\\nno more to do with you   \n",
       "35918  \\n\\n“Let her go back on the labboard! Ting-a-ling-ling! Chow-ch-chow-chow!”\\n The left hand began to describe circles. \\n\\n“Stop the stabboard! Ting-a-ling-ling! Stop the labboard! Come ahead on\\nthe stabboard! Stop her! Let your outside turn over slow! Ting-a-ling-ling!\\nChow-ow-ow! Get out that head-line! _lively_ now! Come—out with\\nyour spring-line—what’re you about there! Take a turn round that stump\\nwith the bight of it! Stand by that stage, now—let her go! Done with\\nthe engines, sir! Ting-a-ling-ling! SH’T! S’H’T! SH’T!” (trying the\\ngauge-cocks)   \n",
       "33653                                                                                                                                                                                                                                                                                                           ”\\n\\n“Speak, and freely.   I will tell you. ”\\n\\n“It will be difficult--perhaps impossible. ”\\n\\n“My art knoweth not that word.   The more difficult it is, the more\\ncertainly will I reveal it to you. ”\\n\\n“The fortune is mine!  I will tell you what you would know   \n",
       "\n",
       "        author author_predicted  \n",
       "index                            \n",
       "1434     defoe          dickens  \n",
       "6896     defoe            twain  \n",
       "10320  dickens            twain  \n",
       "10397  dickens            defoe  \n",
       "22928    doyle            twain  \n",
       "22103    doyle          dickens  \n",
       "35918    twain          dickens  \n",
       "33653    twain            doyle  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ev['author_predicted'] = Y_hat_ev\n",
    "\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(df_ev[df_ev['author'] != df_ev['author_predicted']].groupby('author').sample(2, random_state=288)[['text', 'author', 'author_predicted']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
